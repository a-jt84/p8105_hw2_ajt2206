---
title: "p8105_hw2_ajt2206"
author: "Andy Turner"
date: "2023-09-29"
output: github_document
---
**Libraries**
```{r}
library(tidyverse)
```

## Problem 1

Importing data into R
```{r}
pols_df=
  read_csv("data/pols-month.csv") |> 
  janitor::clean_names() |> 
  separate(mon, into=c("year", "month", "day"), sep= "-") |> 
  mutate(
    month= case_match(
      month,
      "01" ~ "January",
      "02" ~ "February",
      "03" ~ "March",
      "04" ~ "April",
      "05" ~ "May",
      "06" ~ "June",
      "07" ~ "July", 
      "08" ~ "August",
      "09" ~ "September",
      "10"~ "October",
      "11"~ "November",
      "12"~ "December"
    )
  ) |> 
  mutate(
    prez_dem= case_match(
      prez_dem,
      0 ~ "GOP",
      1 ~ "DEM"
    ),
    president = prez_dem) |> 
  mutate(
    year= as.numeric(year)
  ) |> 
  select(-prez_gop, -prez_dem, -day)
```
Steps to import the data:

1. Used `read_csv` to bring data from my file path to R. 

1. Used `clean_names()` to get all variable names in similar format. 

1. Separated the date variable into three separate variables.

1. Recoded the month from number to month name. 

1. Collapsed the prez_gop and prez_dem variables into president variable and also changed the data to be more identifiable "GOP"/"DEM"

1. Converted year from character to numeric variable.

1. Removed prez_gop, prez_dem, and day variables. 

```{r}
snp_df=
  read_csv("data/snp.csv") |> 
  janitor::clean_names() |> 
  separate(date, into = c("month", "day", "year"), sep= "/") |> 
  mutate(
     month= case_match(
      month,
      "1" ~ "January",
      "2" ~ "February",
      "3" ~ "March",
      "4" ~ "April",
      "5" ~ "May",
      "6" ~ "June",
      "7" ~ "July", 
      "8" ~ "August",
      "9" ~ "September",
      "10"~ "October",
      "11"~ "November",
      "12"~ "December"
    ),
    year= as.numeric(year),
    year = ifelse(year <= 23, year + 2000, year + 1900)
  ) |> 
  select(year, month, close)
```
Steps to import the data:

1. Used `read_csv` to bring data from my file path to R. 

1. Used `clean_names()` to get all variable names in similar format. 

1. Separated the date variable into three separate variables.

1. Recoded the month from number to month name. 

1. Converted year from character to numeric variable.

1. Added 2000 or 1900 to the years to convert them from YY to YYYY.

1. Reordered the data so year and month come first. 

```{r}
unemployment_df=
  read_csv("data/unemployment.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment_rate",
  ) |> 
   mutate(
     month= case_match(
      month,
      "jan" ~ "January",
      "feb" ~ "February",
      "mar" ~ "March",
      "apr" ~ "April",
      "may" ~ "May",
      "jun" ~ "June",
      "jul" ~ "July", 
      "aug" ~ "August",
      "sep" ~ "September",
      "oct"~ "October",
      "nov"~ "November",
      "dec"~ "December"
    )
  )
```
Steps to import the data:

1. Used `read_csv` to bring data from my file path to R. 

1. Used `clean_names()` to get all variable names in similar format. 

1. Used `pivot_longer` to change the dataset from horizontal to vertical. Month names moved to "month" and the values moved to "unemployment_rate"

1. Recoded the month from month abbreviation to month name. 


```{r}
data_538 = 
  left_join(pols_df, snp_df) |>
  left_join(x = _, y = unemployment_df)
```
Combined the datasets! Because I did not specify by what variable, they were combined by the common variables of "month" and "year".

**Description of the data**
Pols_df: 
The `pols_df` data has `r nrow(pols_df)` observations and `r ncol(pols_df)` variables. The dataset describes about the breakdown between democrat and republican politicians: governors, senators, and presidents. 

Snp_df:
The `snp_df` data has `r nrow(snp_df)` observations and `r ncol(snp_df)` variables, ranging from years `r snp_df |> pull(year) |> min()` to `r snp_df |> pull(year) |> max()`. 

Unemployment_df
The `unemployment_df` data has `r nrow(unemployment_df)` observations and `r ncol(unemployment_df)` variables ranging from years `r unemployment_df |> pull(year) |> min()` to `r unemployment_df |> pull(year) |> max()`. 

## Problem 2

**Reading and Cleaning the Mr. Trash Wheel data**

Prior to importing the Mr. Trash Wheel data into R, I checked the excel file. The "Year" column had an error where the numeric year was stored as text. I converted the column data to numeric format within Excel (Professor and Gwynnda already had these values stored as numeric). 

```{r}
mr_trash_df=
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet= "Mr. Trash Wheel", range="A2:N586") |> 
  janitor::clean_names() |> 
  mutate(homes_powered= weight_tons*500/30) |>
  mutate(homes_powered= round(homes_powered)) |> 
  mutate(wheel= "Mr. Trash Wheel") |> 
  select(wheel, everything())
```
To read-in and clean up the Mr. Trash Wheel data set, I performed the following steps:

1. Used the `readxl` to read in the data, restricting the import to only include the Mr. Trash Wheel sheet and to columns/rows with data. 

1. `clean_names()` was used to make sure all the imported variables were consistently named. 

1. I overwrote existing values in homes_powered using the equation found in Homes Powered Note in the original excel file. 

1. Because we are looking for an approximation of homes_powered, I rounded the values in homes_powered to the nearest whole number make the data more easily readable using `round(0)`. 

1. I created a new variable "wheel" to help identify each trash wheel's data once combined. 

1. Last, I re-ordered the data frame slightly to put the wheel variable first to simply make the rows more identifiable once combined as well. 

**Reading and Cleaning the Professor and Gwynnda Trash Wheel Data**
```{r}
prof_trash_df=
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet= "Professor Trash Wheel", range="A2:M108") |> 
  janitor::clean_names() |> 
  mutate(homes_powered= weight_tons*500/30) |> 
  mutate(homes_powered= round(homes_powered)) |>
  mutate(wheel= "Professor Trash Wheel") |> 
 select(wheel, everything())

gwynnda_trash_df=
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet= "Gwynnda Trash Wheel", range="A2:L157") |> 
  janitor::clean_names() |> 
  mutate(homes_powered= weight_tons*500/30) |> 
  mutate(homes_powered= round(homes_powered)) |>
  mutate(wheel= "Gwynnda Trash Wheel") |> 
 select(wheel, everything())
```
Same steps as described above for Mr. Trash Wheel data were repeated for the Professor and Gwynnda Trash Wheels. 

**Combining the three datasets**
```{r}
triple_trash_df=
  bind_rows(mr_trash_df, prof_trash_df, gwynnda_trash_df)
```
To combine the datasets, I used the `bind_rows()` function. The datasets were essentially set on top on one another, but since we have the "wheel" variable, it is easy to tell the origin of each observation. 


**Description of the Data**

* This dataset provides data from May 2014 to August 2018 on the trash collected by three Trash Wheels situated in the Inner Harbor in Baltimore, Maryland. There are `r nrow(triple_trash_df)` observations and `r ncol(triple_trash_df)` variables within this dataset. The variables are as follows `r names(triple_trash_df)`. Key variables include the following. `wheel`: identifies which of the three trash wheels the row corresponds to. `weight_tons`: how much trash in tons in each dumpster. `homes_powered`: an estimation of how many Maryland homes are powered by the trash collected per dumpster. Professor Trash Wheel collected `r filter(triple_trash_df, wheel== "Professor Trash Wheel") |> pull(weight_tons) |> sum()` tons of trash as of September 2023. Moreover, Gwynnda Trash Wheel collected a total of `r filter(triple_trash_df, wheel== "Gwynnda Trash Wheel", month == "July", year == "2021") |> pull(cigarette_butts) |> sum()` cigarette butts during the month of July 2021. 

## Problem 3

**Importing and cleaning MCI Baseline Data**
```{r}
mci_baseline_df=
  readxl::read_excel("data/mci_baseline.xlsx", range="A2:F485") |> 
  janitor::clean_names() |> 
  mutate(
    sex= case_match(
      sex,
      0 ~ "Female",
      1 ~ "Male")
  ) |> 
  mutate(
   apoe4= case_match(
      apoe4,
      0 ~ "Non-carrier",
      1 ~ "Carrier")
  ) |> 
  filter(current_age != age_at_onset)
```
To read-in and clean up the MCI Baseline data set, I performed the following steps:

1. Used the `readxl` to read in the data, restricting the import to only include the columns and rows with data along with the variable names. 

1. `clean_names()` was used to make sure all the imported variables were consistently named. 

1. I changed "sex" from being stored as a binary numeric value to a character vector better identifying which participants are Male vs. Female. 

1. I changed "apoe4" from being stored as a binary numeric value to a character vector better identifying which participants are Carriers vs. Non-Carriers. 

1. As part of the study inclusion criteria, participants had to be free of MCI at study baseline. To make sure participants were free of MCI, I filtered the data to only include participants whose age at study baseline was different that their age of MCI onset. 


**Description of the import process and dataset**

`r nrow(mci_baseline_df)` participants met the inclusion criteria of the study and were included in the data. One participant was excluded as they had mci at Baseline. Of the `r nrow(mci_baseline_df)` participants, `r filter(mci_baseline_df, age_at_onset != ".") |> nrow()` went on to develop mci. The average baseline age is `r mci_baseline_df |> pull(current_age) |> mean() |> round(2)` years old. `r round(filter(mci_baseline_df, sex == "Female", apoe4 == "Carrier") |> nrow() / filter(mci_baseline_df, sex == "Female") |> nrow() * 100, 2)` % of the women in the study are APOE4 carriers. 

```{r}
mci_amyloid_df=
  readxl::read_excel("data/mci_amyloid.xlsx", range="A2:F489") |> 
  janitor::clean_names() |> 
  rename(id=study_id) |> 
  pivot_longer(
    baseline:time_8,
    names_to = "yrs_since_baseline",
    values_to = "amyloid_ratio",
    names_prefix= "time_"
  ) |> 
  mutate(
   yrs_since_baseline= replace(yrs_since_baseline, yrs_since_baseline== "baseline", "0"),
  amyloid_ratio= as.numeric(amyloid_ratio)
  )

```
To read-in and clean up the MCI Amyloid data set, I performed the following steps:

1. Used the `readxl` to read in the data, restricting the import to only include the columns and rows with data along with the variable names. 

1. `clean_names()` was used to make sure all the imported variables were consistently named. 

1. I renamed the "study_id" variable to "id" to reflect the naming convention in the `mci_baseline_df` dataset.  

1. I changed "apoe4" from being stored as a binary numeric value to a character vector better identifying which participants are Carriers vs. Non-Carriers. 

1. Originally the data was in horizontal format, I decided to use `pivot_longer()` to switch it to vertical. The variable names (baseline: time_8) became values of the "yrs_since_baseline" variable, and the values were filled into the new "amyloid_ratio" variable. Additionally while pivoting, I removed the "time_" prefix.

1. I renamed "baseline" to "0" to ensure that the "yrs_since_baseline" variable had consistent value formatting throughout.

1. I changed the "amyloid_ratio" from a character to numeric variable. 

*Features of the dataset**

There are `r nrow(mci_amyloid_df)/5` participants in the dataset corresponding to `r nrow(mci_amyloid_df)` observations overall as each participant has 5 observations of data. There are `r ncol(mci_amyloid_df)` variables in the dataset. The variables are as follows: `r names(mci_amyloid_df)`. id: corresponds to participant id in the study; yrs_since_baseline: Time (in years) elapsed since the study baseline to the visit where biomarker Amyloid _ 42/40 ratio was measured; amyloid_ratio: the amyloid ratio measured

```{r}
base_unique = anti_join(mci_baseline_df, mci_amyloid_df) 

amyl_unique= anti_join(mci_amyloid_df,mci_baseline_df)|> 
  distinct(id, .keep_all= TRUE)
```
**Unique Participants**

To find out the number of unique participants, I decided to use `anti_join` and make two new datasets that are populated by the unique values in MCI baseline (base_unique) and MCI amyloid dataset (amyl_unique). 

`r nrow(base_unique)` participants appear only only in the baseline dataset and `r nrow(amyl_unique)` participants appear only in the amyloid dataset.


```{r}
mci_combined_df=
  inner_join(mci_baseline_df, mci_amyloid_df, by= "id")
```
To combine datasets in a way in which only participants who appear in both datasets were retained, I used the `inner_join` feature and joined them by "id".

**Description of the combined dataset**
There are `r nrow(mci_combined_df)/5` participants in the dataset corresponding to `r nrow(mci_combined_df)` observations overall as each participant has 5 observations of data. There are `r ncol(mci_combined_df)` variables in the dataset.

Participant age at baseline spanned from `r mci_combined_df |> pull(current_age) |> min()` to `r mci_combined_df |> pull(current_age) |> max()`years old. APOE Carriers had an average amyloid ratio of `r filter(mci_combined_df, apoe4== "Carrier", amyloid_ratio != "NA") |> pull(amyloid_ratio) |> mean()` while Non-Carriers had an average ratio of `r filter(mci_combined_df, apoe4== "Non-carrier", amyloid_ratio != "NA") |> pull(amyloid_ratio) |> mean()`.

**Exporting the result as a CSV**

```{r}
write.csv(mci_combined_df, file = "data/mci_combined_df.csv", row.names = FALSE)
```
I used `write.csv` to export my new csv file. I added a `row.names=FALSE` statement as I did not want to add the row number to the csv document. 
