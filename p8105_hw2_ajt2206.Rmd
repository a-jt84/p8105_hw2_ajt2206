---
title: "p8105_hw2_ajt2206"
author: "Andy Turner"
date: "2023-09-29"
output: github_document
---
**Libraries**
```{r}
library(tidyverse)
```



## Problem 1

Importing data into R
```{r}
pols_df=
  read_csv("data/pols-month.csv") |> 
  janitor::clean_names() |> 
  separate(mon, into=c("year", "month", "day"), sep= "-") |> 
  mutate(
    month= case_match(
      month,
      "01" ~ "January",
      "02" ~ "February",
      "03" ~ "March",
      "04" ~ "April",
      "05" ~ "May",
      "06" ~ "June",
      "07" ~ "July", 
      "08" ~ "August",
      "09" ~ "September",
      "10"~ "October",
      "11"~ "November",
      "12"~ "December"
    )
  ) |> 
  mutate(
    prez_dem= case_match(
      prez_dem,
      0 ~ "GOP",
      1 ~ "DEM"
    )
  ) |> 
  mutate(president = prez_dem) |> 
  select(-prez_gop, -prez_dem, -day)
 
```

## Problem 2

**Reading and Cleaning the Mr. Trash Wheel data**

Prior to importing the Mr. Trash Wheel data into R, I checked the excel file. The "Year" column had an error where the numeric year was stored as text. I converted the column data to numeric format within Excel (Professor and Gwynnda already had these values stored as numeric). 

```{r}
mr_trash_df=
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet= "Mr. Trash Wheel", range="A2:N586") |> 
  janitor::clean_names() |> 
  mutate(homes_powered= weight_tons*500/30) |>
  mutate(homes_powered= round(homes_powered)) |> 
  mutate(wheel= "Mr. Trash Wheel") |> 
  select(wheel, everything())
```
To read-in and clean up the Mr. Trash Wheel data set, I performed the following steps:

1. Used the `readxl` to read in the data, restricting the import to only include the Mr. Trash Wheel sheet and to rows with data. 

1. `clean_names()` was used to make sure all the imported variables were consistently named. 

1. I overwrote existing values in homes_powered using the equation found in Homes Powered Note in the original excel file. 

1. Because we are looking for an approximation of homes_powered, I rounded the values in homes_powered to the nearest whole number make the data more easily readable using `round(0)`. 

1. I created a new variable "wheel" to help identify each trash wheel's data once combined. 

1. Last, I re-ordered the data frame slightly to put the wheel variable first to simply make the rows more identifiable once combined as well. 

**Reading and Cleaning the Professor and Gwynnda Trash Wheel Data**
```{r}
prof_trash_df=
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet= "Professor Trash Wheel", range="A2:M108") |> 
  janitor::clean_names() |> 
  mutate(homes_powered= weight_tons*500/30) |> 
  mutate(homes_powered= round(homes_powered)) |>
  mutate(wheel= "Professor Trash Wheel") |> 
 select(wheel, everything())

gwynnda_trash_df=
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet= "Gwynnda Trash Wheel", range="A2:L157") |> 
  janitor::clean_names() |> 
  mutate(homes_powered= weight_tons*500/30) |> 
  mutate(homes_powered= round(homes_powered)) |>
  mutate(wheel= "Gwynnda Trash Wheel") |> 
 select(wheel, everything())
```
Same steps as described above for Mr. Trash Wheel data were repeated for the Professor and Gwynnda Trash Wheels. 

**Combining the three datasets**
```{r}
triple_trash_df=
  bind_rows(mr_trash_df, prof_trash_df, gwynnda_trash_df)
```
To combine the datasets, I used the `bind_rows()` function. The datasets were essentially set on top on one another, but since we have the "wheel" variable, it is easy to tell the origin of each observation. 


**Description of the Data**

* This dataset provides data from May 2014 to August 2018 on the trash collected by three Trash Wheels situated in the Inner Harbor in Baltimore, Maryland. There are `r nrow(triple_trash_df)` observations and `r ncol(triple_trash_df)` variables within this dataset. The variables are as follows `r names(triple_trash_df)`. Key variables include the following. `wheel`: identifies which of the three trash wheels the row corresponds to. `weight_tons`: how much trash in tons in each dumpster. `homes_powered`: an estimation of how many Maryland homes are powered by the trash collected per dumpster. Professor Trash Wheel collected `r filter(triple_trash_df, wheel== "Professor Trash Wheel") |> pull(weight_tons) |> sum()`tons of trash as of September 2023. Moreover, Gwynnda Trash Wheel collected a total of `r filter(triple_trash_df, wheel== "Gwynnda Trash Wheel", month == "July", year == "2021") |> pull(cigarette_butts) |> sum()` cigarette butts during the month of July 2021. 

## Problem 3

```{r}
mci_baseline_df=
  readxl::read_excel("data/mci_baseline.xlsx", range="A2:F485") |> 
  janitor::clean_names() |> 
  mutate(
    sex= case_match(
      sex,
      0 ~ "Female",
      1 ~ "Male")
  ) |> 
  mutate(
   apoe4= case_match(
      apoe4,
      0 ~ "Non-carrier",
      1 ~ "Carrier")
  ) |> 
  filter(current_age != age_at_onset)
```
**Description of the import process and dataset**

`r nrow(mci_baseline_df)` participants met the inclusion criteria of the study and were included in the data. One participant was excluded as they had mci at Baseline. Of the `r nrow(mci_baseline_df)` participants, `r filter(mci_baseline_df, age_at_onset != ".") |> nrow()` went on to develop mci. The average baseline age is `r mci_baseline_df |> pull(current_age) |> mean()` years old. `r filter(mci_baseline_df, sex == "Female", apoe4 == "Carrier") |> nrow() / filter(mci_baseline_df, sex == "Female") |> nrow() * 100` % of the women in the study are APOE4 carriers. 

```{r}
mci_amyloid_df=
  readxl::read_excel("data/mci_amyloid.xlsx", range="A2:F489") |> 
  janitor::clean_names() |> 
  rename(id=study_id)
```

Similarly, import, clean, and tidy the dataset of longitudinally observed biomarker values; comment on the steps on the import process and the features of the dataset.

Check whether some participants appear in only the baseline or amyloid datasets, and comment on your findings. Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained, and briefly describe the resulting dataset; export the result as a CSV to your data directory

```{r}
mci_combined_df=
  inner_join(mci_baseline_df, mci_amyloid_df, by= "id")
```

