p8105_hw2_ajt2206
================
Andy Turner
2023-09-29

**Libraries**

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.2     ✔ readr     2.1.4
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.0
    ## ✔ ggplot2   3.4.2     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
    ## ✔ purrr     1.0.1     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

## Problem 1

Importing data into R

``` r
pols_df=
  read_csv("data/pols-month.csv") |> 
  janitor::clean_names() |> 
  separate(mon, into=c("year", "month", "day"), sep= "-") |> 
  mutate(
    month= case_match(
      month,
      "01" ~ "January",
      "02" ~ "February",
      "03" ~ "March",
      "04" ~ "April",
      "05" ~ "May",
      "06" ~ "June",
      "07" ~ "July", 
      "08" ~ "August",
      "09" ~ "September",
      "10"~ "October",
      "11"~ "November",
      "12"~ "December"
    )
  ) |> 
  mutate(
    prez_dem= case_match(
      prez_dem,
      0 ~ "GOP",
      1 ~ "DEM"
    ),
    president = prez_dem) |> 
  mutate(
    year= as.numeric(year)
  ) |> 
  select(-prez_gop, -prez_dem, -day)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Steps to import the data:

1.  Used `read_csv` to bring data from my file path to R.

2.  Used `clean_names()` to get all variable names in similar format.

3.  Separated the date variable into three separate variables.

4.  Recoded the month from number to month name.

5.  Collapsed the prez_gop and prez_dem variables into president
    variable and also changed the data to be more identifiable
    “GOP”/“DEM”

6.  Converted year from character to numeric variable.

7.  Removed prez_gop, prez_dem, and day variables.

``` r
snp_df=
  read_csv("data/snp.csv") |> 
  janitor::clean_names() |> 
  separate(date, into = c("month", "day", "year"), sep= "/") |> 
  mutate(
     month= case_match(
      month,
      "1" ~ "January",
      "2" ~ "February",
      "3" ~ "March",
      "4" ~ "April",
      "5" ~ "May",
      "6" ~ "June",
      "7" ~ "July", 
      "8" ~ "August",
      "9" ~ "September",
      "10"~ "October",
      "11"~ "November",
      "12"~ "December"
    ),
    year= as.numeric(year),
    year = ifelse(year <= 23, year + 2000, year + 1900)
  ) |> 
  select(year, month, close)
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Steps to import the data:

1.  Used `read_csv` to bring data from my file path to R.

2.  Used `clean_names()` to get all variable names in similar format.

3.  Separated the date variable into three separate variables.

4.  Recoded the month from number to month name.

5.  Converted year from character to numeric variable.

6.  Added 2000 or 1900 to the years to convert them from YY to YYYY.

7.  Reordered the data so year and month come first.

``` r
unemployment_df=
  read_csv("data/unemployment.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment_rate",
  ) |> 
   mutate(
     month= case_match(
      month,
      "jan" ~ "January",
      "feb" ~ "February",
      "mar" ~ "March",
      "apr" ~ "April",
      "may" ~ "May",
      "jun" ~ "June",
      "jul" ~ "July", 
      "aug" ~ "August",
      "sep" ~ "September",
      "oct"~ "October",
      "nov"~ "November",
      "dec"~ "December"
    )
  )
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Steps to import the data:

1.  Used `read_csv` to bring data from my file path to R.

2.  Used `clean_names()` to get all variable names in similar format.

3.  Used `pivot_longer` to change the dataset from horizontal to
    vertical. Month names moved to “month” and the values moved to
    “unemployment_rate”

4.  Recoded the month from month abbreviation to month name.

``` r
data_538 = 
  left_join(pols_df, snp_df) |>
  left_join(x = _, y = unemployment_df)
```

    ## Joining with `by = join_by(year, month)`
    ## Joining with `by = join_by(year, month)`

Combined the datasets! Because I did not specify by what variable, they
were combined by the common variables of “month” and “year”.

**Description of the data** Pols_df: The `pols_df` data has 822
observations and 9 variables. The dataset describes about the breakdown
between democrat and republican politicians: governors, senators, and
presidents.

Snp_df: The `snp_df` data has 787 observations and 3 variables, ranging
from years 1950 to 2015.

Unemployment_df The `unemployment_df` data has 816 observations and 3
variables ranging from years 1948 to 2015.

## Problem 2

**Reading and Cleaning the Mr. Trash Wheel data**

Prior to importing the Mr. Trash Wheel data into R, I checked the excel
file. The “Year” column had an error where the numeric year was stored
as text. I converted the column data to numeric format within Excel
(Professor and Gwynnda already had these values stored as numeric).

``` r
mr_trash_df=
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet= "Mr. Trash Wheel", range="A2:N586") |> 
  janitor::clean_names() |> 
  mutate(homes_powered= weight_tons*500/30) |>
  mutate(homes_powered= round(homes_powered)) |> 
  mutate(wheel= "Mr. Trash Wheel") |> 
  select(wheel, everything())
```

To read-in and clean up the Mr. Trash Wheel data set, I performed the
following steps:

1.  Used the `readxl` to read in the data, restricting the import to
    only include the Mr. Trash Wheel sheet and to columns/rows with
    data.

2.  `clean_names()` was used to make sure all the imported variables
    were consistently named.

3.  I overwrote existing values in homes_powered using the equation
    found in Homes Powered Note in the original excel file.

4.  Because we are looking for an approximation of homes_powered, I
    rounded the values in homes_powered to the nearest whole number make
    the data more easily readable using `round(0)`.

5.  I created a new variable “wheel” to help identify each trash wheel’s
    data once combined.

6.  Last, I re-ordered the data frame slightly to put the wheel variable
    first to simply make the rows more identifiable once combined as
    well.

**Reading and Cleaning the Professor and Gwynnda Trash Wheel Data**

``` r
prof_trash_df=
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet= "Professor Trash Wheel", range="A2:M108") |> 
  janitor::clean_names() |> 
  mutate(homes_powered= weight_tons*500/30) |> 
  mutate(homes_powered= round(homes_powered)) |>
  mutate(wheel= "Professor Trash Wheel") |> 
 select(wheel, everything())

gwynnda_trash_df=
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet= "Gwynnda Trash Wheel", range="A2:L157") |> 
  janitor::clean_names() |> 
  mutate(homes_powered= weight_tons*500/30) |> 
  mutate(homes_powered= round(homes_powered)) |>
  mutate(wheel= "Gwynnda Trash Wheel") |> 
 select(wheel, everything())
```

Same steps as described above for Mr. Trash Wheel data were repeated for
the Professor and Gwynnda Trash Wheels.

**Combining the three datasets**

``` r
triple_trash_df=
  bind_rows(mr_trash_df, prof_trash_df, gwynnda_trash_df)
```

To combine the datasets, I used the `bind_rows()` function. The datasets
were essentially set on top on one another, but since we have the
“wheel” variable, it is easy to tell the origin of each observation.

**Description of the Data**

- This dataset provides data from May 2014 to August 2018 on the trash
  collected by three Trash Wheels situated in the Inner Harbor in
  Baltimore, Maryland. There are 845 observations and 15 variables
  within this dataset. The variables are as follows wheel, dumpster,
  month, year, date, weight_tons, volume_cubic_yards, plastic_bottles,
  polystyrene, cigarette_butts, glass_bottles, plastic_bags, wrappers,
  sports_balls, homes_powered. Key variables include the following.
  `wheel`: identifies which of the three trash wheels the row
  corresponds to. `weight_tons`: how much trash in tons in each
  dumpster. `homes_powered`: an estimation of how many Maryland homes
  are powered by the trash collected per dumpster. Professor Trash Wheel
  collected 216.26 tons of trash as of September 2023. Moreover, Gwynnda
  Trash Wheel collected a total of 1.63^{4} cigarette butts during the
  month of July 2021.

## Problem 3

**Importing and cleaning MCI Baseline Data**

``` r
mci_baseline_df=
  readxl::read_excel("data/mci_baseline.xlsx", range="A2:F485") |> 
  janitor::clean_names() |> 
  mutate(
    sex= case_match(
      sex,
      0 ~ "Female",
      1 ~ "Male")
  ) |> 
  mutate(
   apoe4= case_match(
      apoe4,
      0 ~ "Non-carrier",
      1 ~ "Carrier")
  ) |> 
  filter(current_age != age_at_onset)
```

To read-in and clean up the MCI Baseline data set, I performed the
following steps:

1.  Used the `readxl` to read in the data, restricting the import to
    only include the columns and rows with data along with the variable
    names.

2.  `clean_names()` was used to make sure all the imported variables
    were consistently named.

3.  I changed “sex” from being stored as a binary numeric value to a
    character vector better identifying which participants are Male
    vs. Female.

4.  I changed “apoe4” from being stored as a binary numeric value to a
    character vector better identifying which participants are Carriers
    vs. Non-Carriers.

5.  As part of the study inclusion criteria, participants had to be free
    of MCI at study baseline. To make sure participants were free of
    MCI, I filtered the data to only include participants whose age at
    study baseline was different that their age of MCI onset.

**Description of the import process and dataset**

482 participants met the inclusion criteria of the study and were
included in the data. One participant was excluded as they had mci at
Baseline. Of the 482 participants, 96 went on to develop mci. The
average baseline age is 65.04 years old. 29.86 % of the women in the
study are APOE4 carriers.

``` r
mci_amyloid_df=
  readxl::read_excel("data/mci_amyloid.xlsx", range="A2:F489") |> 
  janitor::clean_names() |> 
  rename(id=study_id) |> 
  pivot_longer(
    baseline:time_8,
    names_to = "yrs_since_baseline",
    values_to = "amyloid_ratio",
    names_prefix= "time_"
  ) |> 
  mutate(
   yrs_since_baseline= replace(yrs_since_baseline, yrs_since_baseline== "baseline", "0"),
  amyloid_ratio= as.numeric(amyloid_ratio)
  )
```

    ## Warning: There was 1 warning in `mutate()`.
    ## ℹ In argument: `amyloid_ratio = as.numeric(amyloid_ratio)`.
    ## Caused by warning:
    ## ! NAs introduced by coercion

To read-in and clean up the MCI Amyloid data set, I performed the
following steps:

1.  Used the `readxl` to read in the data, restricting the import to
    only include the columns and rows with data along with the variable
    names.

2.  `clean_names()` was used to make sure all the imported variables
    were consistently named.

3.  I renamed the “study_id” variable to “id” to reflect the naming
    convention in the `mci_baseline_df` dataset.

4.  I changed “apoe4” from being stored as a binary numeric value to a
    character vector better identifying which participants are Carriers
    vs. Non-Carriers.

5.  Originally the data was in horizontal format, I decided to use
    `pivot_longer()` to switch it to vertical. The variable names
    (baseline: time_8) became values of the “yrs_since_baseline”
    variable, and the values were filled into the new “amyloid_ratio”
    variable. Additionally while pivoting, I removed the “time\_”
    prefix.

6.  I renamed “baseline” to “0” to ensure that the “yrs_since_baseline”
    variable had consistent value formatting throughout.

7.  I changed the “amyloid_ratio” from a character to numeric variable.

\*Features of the dataset\*\*

There are 487 participants in the dataset corresponding to 2435
observations overall as each participant has 5 observations of data.
There are 3 variables in the dataset. The variables are as follows: id,
yrs_since_baseline, amyloid_ratio. id: corresponds to participant id in
the study; yrs_since_baseline: Time (in years) elapsed since the study
baseline to the visit where biomarker Amyloid \_ 42/40 ratio was
measured; amyloid_ratio: the amyloid ratio measured

``` r
base_unique = anti_join(mci_baseline_df, mci_amyloid_df) 
```

    ## Joining with `by = join_by(id)`

``` r
amyl_unique= anti_join(mci_amyloid_df,mci_baseline_df)|> 
  distinct(id, .keep_all= TRUE)
```

    ## Joining with `by = join_by(id)`

**Unique Participants**

To find out the number of unique participants, I decided to use
`anti_join` and make two new datasets that are populated by the unique
values in MCI baseline (base_unique) and MCI amyloid dataset
(amyl_unique).

8 participants appear only only in the baseline dataset and 13
participants appear only in the amyloid dataset.

``` r
mci_combined_df=
  inner_join(mci_baseline_df, mci_amyloid_df, by= "id")
```

To combine datasets in a way in which only participants who appear in
both datasets were retained, I used the `inner_join` feature and joined
them by “id”.

**Description of the combined dataset** There are 474 participants in
the dataset corresponding to 2370 observations overall as each
participant has 5 observations of data. There are 8 variables in the
dataset.

Participant age at baseline spanned from 56 to 72.9years old. APOE
Carriers had an average amyloid ratio of 0.107322 while Non-Carriers had
an average ratio of 0.1106822.

**Exporting the result as a CSV**

``` r
write.csv(mci_combined_df, file = "data/mci_combined_df.csv", row.names = FALSE)
```

I used `write.csv` to export my new csv file. I added a
`row.names=FALSE` statement as I did not want to add the row number to
the csv document.
